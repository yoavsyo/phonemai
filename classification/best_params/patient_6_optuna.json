{
    "hidden_size": 306,
    "num_lstm_layers": 3,
    "num_fc_layers": 3,
    "dropout_prob": 0.1,
    "weight_decay": 4.2204191132691505e-07,
    "learning_rate": 0.0003825700458965812,
    "batch_size": 8,
    "epochs": 47
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYjYLlIz1irA",
        "outputId": "2bcb13c8-42ef-406b-dd9f-63fda2c53ef5"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7FVY04t1kpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dXfBgqO01nN8",
        "outputId": "3457fd50-770a-48a3-bf00-3f51b83c1c17"
      },
      "outputs": [],
      "source": [
        "# Load the .pt files\n",
        "mat_path = '/content/drive/MyDrive/data_detect/mat.pt'\n",
        "labels_path = '/content/drive/MyDrive/data_detect/labels.pt'\n",
        "model_path = '/content/drive/MyDrive/data_detect/trained_model.pth'\n",
        "mat_tensor = torch.load(mat_path)\n",
        "labels_tensor = torch.load(labels_path)\n",
        "\n",
        "# Verify the loaded tensors\n",
        "print(\"Shape of mat_tensor:\", mat_tensor.shape)\n",
        "print(\"Shape of labels_tensor:\", labels_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L42EN2XLe40p"
      },
      "outputs": [],
      "source": [
        "input_size = 12  # Size of each input feature vector (number of channels)\n",
        "hidden_size = 50  # Number of features in the hidden state\n",
        "output_size = 1  # Binary output (speech detected or not)\n",
        "num_layers = 1  # Number of LSTM layers\n",
        "seq_length = 300  # Number of time bins to remember\n",
        "batch_size = 32  # Batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS9bJsflu4nQ"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "class SpeechLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(SpeechLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, h0, c0):\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)  # Use the output of the LSTM\n",
        "        return out, hn, cn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZhZAzZiu8Be"
      },
      "outputs": [],
      "source": [
        "# Prepare the data to include sequences of `seq_length`\n",
        "def create_sequences(data, labels, seq_length):\n",
        "    sequences = []\n",
        "    seq_labels = []\n",
        "    for i in range(0, len(data) - seq_length + 1, seq_length):\n",
        "        sequences.append(data[i:i + seq_length])\n",
        "        seq_labels.append(labels[i:i + seq_length])\n",
        "    return torch.stack(sequences), torch.stack(seq_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g31ydGxf1pDE",
        "outputId": "8eb2a38b-ea53-4fd8-e572-00eb65609720"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Create the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SpeechLSTM(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming mat_tensor and labels_tensor are already defined and preprocessed\n",
        "# Create sequences\n",
        "X_seq, y_seq = create_sequences(mat_tensor, labels_tensor, seq_length)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq, y_seq, test_size=0.2)\n",
        "X_train_seq = X_train_seq.to(device)\n",
        "y_train_seq = y_train_seq.to(device)\n",
        "X_test_seq = X_test_seq.to(device)\n",
        "y_test_seq = y_test_seq.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 60\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "eval_losses = []\n",
        "eval_accuracies = []\n",
        "\n",
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for b in range(0, len(X_train_seq), batch_size):\n",
        "        batch_X = X_train_seq[b:b + batch_size]\n",
        "        batch_y = y_train_seq[b:b + batch_size]\n",
        "        batch_loss = 0\n",
        "        batch_correct = 0\n",
        "        batch_total = 0\n",
        "\n",
        "        h0 = torch.zeros(num_layers, batch_X.size(0), hidden_size).to(device)\n",
        "        c0 = torch.zeros(num_layers, batch_X.size(0), hidden_size).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            X_step = batch_X[:, t, :].unsqueeze(1)\n",
        "            y_step = batch_y[:, t].unsqueeze(1)\n",
        "            outputs, h0, c0 = model(X_step, h0, c0)\n",
        "            outputs = outputs.squeeze(1)  # Remove the sequence dimension\n",
        "            loss = criterion(outputs, y_step)\n",
        "            loss.backward(retain_graph=True)  # Retain graph for multiple time steps\n",
        "            batch_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            batch_correct += (predicted == y_step).sum().item()\n",
        "            batch_total += y_step.size(0)\n",
        "\n",
        "        optimizer.step()\n",
        "        batch_loss /= seq_length\n",
        "        epoch_loss += batch_loss\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "\n",
        "    epoch_loss /= (len(X_train_seq) / batch_size)\n",
        "    train_losses.append(epoch_loss)\n",
        "    accuracy = correct / total\n",
        "    train_accuracies.append(accuracy)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss:.4f}, Average Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    with torch.no_grad():\n",
        "        h0 = torch.zeros(num_layers, X_test_seq.size(0), hidden_size).to(device)\n",
        "        c0 = torch.zeros(num_layers, X_test_seq.size(0), hidden_size).to(device)\n",
        "        for t in range(seq_length):\n",
        "            X_step = X_test_seq[:, t, :].unsqueeze(1)\n",
        "            y_step = y_test_seq[:, t].unsqueeze(1)\n",
        "            print(\"EVAL : Shape of X_step:\", X_step.shape)\n",
        "            print(\"EVAL : Shape of y_step:\", y_step.shape)\n",
        "            outputs, h0, c0 = model(X_step, h0, c0)\n",
        "            outputs = outputs.squeeze(1)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            test_correct += (predicted == y_step).sum().item()\n",
        "            test_total += y_step.size(0)\n",
        "\n",
        "    test_accuracy = test_correct / test_total\n",
        "    eval_accuracies.append(test_accuracy)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "    # Save the model if the test accuracy is the best so far\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model.state_dict(), 'best_speech_lstm_model.pth')\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, num_epochs, epoch_loss, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K11GM-GSvzK1"
      },
      "outputs": [],
      "source": [
        "# Plot training loss and accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(eval_accuracies, label='Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Q6YYZIVGra",
        "outputId": "301735f3-df96-4b25-e60f-5628726988bc"
      },
      "outputs": [],
      "source": [
        "model = SpeechLSTM(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp8XCtLB60bX"
      },
      "outputs": [],
      "source": [
        "# Real-time speech detection class\n",
        "class RealTimeSpeechDetector:\n",
        "    def __init__(self, model, input_size):\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        # self.h0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
        "        # self.c0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
        "        self.h0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
        "        self.c0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
        "\n",
        "    def predict(self, sample):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            output, self.h0, self.c0 = self.model(sample, self.h0, self.c0)\n",
        "        return 1 if output[0, -1, 0].item() > 0.5 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WknKuMV_Xh1O",
        "outputId": "6334875e-853d-497e-f3f2-3461c45bd1a6"
      },
      "outputs": [],
      "source": [
        "print(type(X_test_seq))\n",
        "print(X_test_seq.shape)\n",
        "sequence_test = X_test_seq[0].unsqueeze(0)\n",
        "labels_test = y_test_seq[0]\n",
        "print(sequence_test.shape)\n",
        "print(labels_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJisgS_UyG2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "\n",
        "class RealTimeSpeechDetector:\n",
        "    def __init__(self, model, input_size, hidden_size, num_layers, device):\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "        self.h0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
        "        self.c0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
        "\n",
        "    def predict(self, sample):\n",
        "        self.model.eval()\n",
        "        sample = sample.unsqueeze(0).unsqueeze(0).to(self.device)  # Shape: (1, 1, input_size)\n",
        "        with torch.no_grad():\n",
        "            output, self.h0, self.c0 = self.model(sample, self.h0, self.c0)\n",
        "        return 1 if torch.sigmoid(output).item() > 0.5 else 0\n",
        "\n",
        "# Instantiate the real-time detector with the specified sequence length\n",
        "detector = RealTimeSpeechDetector(model, input_size, hidden_size, num_layers, device)\n",
        "\n",
        "# Add samples in real-time and get predictions for visualization\n",
        "num_time_bins = 300  # Number of time bins to plot\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "# Process the test set\n",
        "for i in range(num_time_bins):\n",
        "    sample = X_test_seq[i % len(X_test_seq), -1, :]  # Get the last time step of the sequence\n",
        "    prediction = detector.predict(sample)  # Use the last sample in the sequence\n",
        "    predictions.append(prediction)\n",
        "    targets.append(y_test_seq[i % len(y_test_seq), -1].item())  # Ensure correct target assignment\n",
        "\n",
        "    # Plot predictions vs targets at each step\n",
        "    if (i + 1) % 10 == 0:  # Save plots every 10 time bins\n",
        "        plt.figure()\n",
        "        plt.plot(range(len(predictions)), predictions, label='Predictions', marker='o')\n",
        "        plt.plot(range(len(targets)), targets[:len(predictions)], label='Targets', marker='x')\n",
        "        plt.title(f'Predictions vs Targets at Time {i}')\n",
        "        plt.xlabel('Sample Index')\n",
        "        plt.ylabel('Speech Detection')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f'plot_{i}.png')\n",
        "        plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
